{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002\tAbnorml\n",
      "1018\tAbnorml\n",
      "1022\tPartial\n",
      "1025\tAbnorml\n",
      "1028\tPartial\n",
      "103\tAlloca\n",
      "1033\tAbnorml\n",
      "1047\tPartial\n",
      "1050\tAbnorml\n",
      "1051\tPartial\n",
      "1052\tPartial\n",
      "1056\tAbnorml\n",
      "1078\tAbnorml\n",
      "108\tPartial\n",
      "1081\tAbnorml\n",
      "1100\tAbnorml\n",
      "1103\tFamily\n",
      "1108\tPartial\n",
      "1109\tAbnorml\n",
      "1116\tPartial\n",
      "1122\tPartial\n",
      "1123\tAbnorml\n",
      "1128\tFamily\n",
      "113\tPartial\n",
      "1132\tAbnorml\n",
      "1137\tAbnorml\n",
      "114\tAbnorml\n",
      "1141\tAbnorml\n",
      "1143\tPartial\n",
      "1146\tFamily\n",
      "1153\tAbnorml\n",
      "1159\tPartial\n",
      "1164\tAlloca\n",
      "1166\tPartial\n",
      "118\tPartial\n",
      "1182\tPartial\n",
      "1183\tAbnorml\n",
      "1187\tAbnorml\n",
      "1197\tPartial\n",
      "12\tPartial\n",
      "120\tPartial\n",
      "1201\tAbnorml\n",
      "1210\tPartial\n",
      "1218\tPartial\n",
      "1220\tAbnorml\n",
      "1221\tAbnorml\n",
      "1229\tPartial\n",
      "1234\tAbnorml\n",
      "1235\tAbnorml\n",
      "1239\tAbnorml\n",
      "1242\tPartial\n",
      "1243\tFamily\n",
      "1244\tPartial\n",
      "1246\tAbnorml\n",
      "1247\tPartial\n",
      "1265\tAbnorml\n",
      "1280\tAbnorml\n",
      "1290\tPartial\n",
      "1298\tPartial\n",
      "1299\tPartial\n",
      "130\tAbnorml\n",
      "1307\tPartial\n",
      "1312\tPartial\n",
      "1318\tPartial\n",
      "1325\tPartial\n",
      "1345\tPartial\n",
      "1348\tPartial\n",
      "1364\tPartial\n",
      "1365\tAbnorml\n",
      "1367\tAbnorml\n",
      "1376\tPartial\n",
      "138\tFamily\n",
      "1388\tFamily\n",
      "1395\tPartial\n",
      "14\tPartial\n",
      "1403\tPartial\n",
      "1405\tFamily\n",
      "1414\tAbnorml\n",
      "1424\tAlloca\n",
      "1429\tAbnorml\n",
      "1436\tAbnorml\n",
      "1438\tPartial\n",
      "145\tAbnorml\n",
      "1450\tAbnorml\n",
      "1452\tPartial\n",
      "1454\tAbnorml\n",
      "152\tPartial\n",
      "155\tFamily\n",
      "158\tPartial\n",
      "160\tPartial\n",
      "163\tPartial\n",
      "168\tPartial\n",
      "179\tPartial\n",
      "189\tAlloca\n",
      "197\tPartial\n",
      "198\tAbnorml\n",
      "199\tAbnorml\n",
      "20\tAbnorml\n",
      "21\tPartial\n",
      "213\tPartial\n",
      "218\tFamily\n",
      "220\tPartial\n",
      "221\tPartial\n",
      "224\tAbnorml\n",
      "226\tAbnorml\n",
      "227\tAbnorml\n",
      "239\tPartial\n",
      "252\tFamily\n",
      "258\tAbnorml\n",
      "262\tPartial\n",
      "271\tPartial\n",
      "279\tPartial\n",
      "282\tPartial\n",
      "284\tPartial\n",
      "286\tPartial\n",
      "291\tPartial\n",
      "300\tFamily\n",
      "304\tAbnorml\n",
      "321\tPartial\n",
      "350\tPartial\n",
      "351\tPartial\n",
      "352\tAbnorml\n",
      "359\tAbnorml\n",
      "379\tPartial\n",
      "382\tPartial\n",
      "387\tAdjLand\n",
      "388\tAbnorml\n",
      "39\tAbnorml\n",
      "390\tPartial\n",
      "394\tAbnorml\n",
      "399\tAbnorml\n",
      "4\tAbnorml\n",
      "40\tAdjLand\n",
      "402\tPartial\n",
      "404\tAbnorml\n",
      "409\tPartial\n",
      "41\tAbnorml\n",
      "410\tPartial\n",
      "411\tAbnorml\n",
      "413\tPartial\n",
      "416\tPartial\n",
      "419\tAdjLand\n",
      "421\tAlloca\n",
      "429\tPartial\n",
      "431\tAbnorml\n",
      "432\tAbnorml\n",
      "444\tPartial\n",
      "455\tFamily\n",
      "457\tAbnorml\n",
      "461\tPartial\n",
      "47\tAbnorml\n",
      "474\tPartial\n",
      "480\tAlloca\n",
      "49\tPartial\n",
      "493\tPartial\n",
      "496\tAbnorml\n",
      "508\tPartial\n",
      "512\tPartial\n",
      "516\tPartial\n",
      "517\tAbnorml\n",
      "524\tPartial\n",
      "528\tPartial\n",
      "530\tAlloca\n",
      "531\tAbnorml\n",
      "545\tPartial\n",
      "551\tAbnorml\n",
      "57\tAbnorml\n",
      "572\tAbnorml\n",
      "573\tPartial\n",
      "576\tAbnorml\n",
      "578\tAbnorml\n",
      "579\tAbnorml\n",
      "582\tPartial\n",
      "586\tPartial\n",
      "589\tPartial\n",
      "59\tPartial\n",
      "596\tPartial\n",
      "598\tPartial\n",
      "603\tAbnorml\n",
      "609\tAlloca\n",
      "61\tPartial\n",
      "614\tPartial\n",
      "616\tAbnorml\n",
      "619\tPartial\n",
      "629\tFamily\n",
      "631\tAbnorml\n",
      "633\tFamily\n",
      "636\tAbnorml\n",
      "640\tPartial\n",
      "645\tPartial\n",
      "656\tFamily\n",
      "659\tAbnorml\n",
      "665\tPartial\n",
      "667\tAbnorml\n",
      "679\tPartial\n",
      "682\tAbnorml\n",
      "687\tPartial\n",
      "689\tPartial\n",
      "694\tAbnorml\n",
      "703\tPartial\n",
      "709\tPartial\n",
      "710\tAbnorml\n",
      "712\tAbnorml\n",
      "729\tAbnorml\n",
      "735\tFamily\n",
      "739\tAlloca\n",
      "741\tAbnorml\n",
      "758\tAbnorml\n",
      "766\tPartial\n",
      "773\tAbnorml\n",
      "775\tPartial\n",
      "777\tPartial\n",
      "794\tPartial\n",
      "798\tAbnorml\n",
      "799\tPartial\n",
      "804\tPartial\n",
      "805\tFamily\n",
      "806\tPartial\n",
      "813\tAlloca\n",
      "820\tPartial\n",
      "823\tFamily\n",
      "825\tPartial\n",
      "826\tPartial\n",
      "829\tAbnorml\n",
      "855\tAbnorml\n",
      "859\tFamily\n",
      "865\tPartial\n",
      "867\tPartial\n",
      "875\tAbnorml\n",
      "876\tPartial\n",
      "88\tPartial\n",
      "886\tAbnorml\n",
      "887\tFamily\n",
      "89\tAbnorml\n",
      "895\tAlloca\n",
      "897\tAbnorml\n",
      "898\tAlloca\n",
      "899\tPartial\n",
      "9\tAbnorml\n",
      "904\tPartial\n",
      "913\tAbnorml\n",
      "915\tPartial\n",
      "917\tAbnorml\n",
      "92\tAbnorml\n",
      "923\tPartial\n",
      "926\tAbnorml\n",
      "939\tPartial\n",
      "943\tAbnorml\n",
      "945\tAbnorml\n",
      "952\tAbnorml\n",
      "955\tAdjLand\n",
      "966\tPartial\n",
      "969\tAbnorml\n",
      "971\tAbnorml\n",
      "974\tPartial\n",
      "978\tPartial\n",
      "979\tAbnorml\n",
      "988\tPartial\n",
      "99\tAbnorml\n",
      "990\tPartial\n",
      "994\tPartial\n",
      "996\tAbnorml\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "filename = \"train.csv\"\n",
    "superDict = defaultdict(dict)\n",
    "headers = dict()\n",
    "count = 0\n",
    "for line in open(filename):\n",
    "\tlineList = line.split(\",\")\n",
    "\tif count == 0:\n",
    "\t\tcnt = 0\n",
    "\t\tfor name in lineList:\n",
    "\t\t\theaders[str(cnt)] = name\n",
    "\t\t\tcnt += 1\n",
    "\telse:\n",
    "\t\tvalueCount = 1\n",
    "\t\tfor values in lineList[1:]:\n",
    "\n",
    "\t\t\tsuperDict[str(lineList[0])][headers[str(valueCount)]] = lineList[valueCount]\n",
    "\t\t\tvalueCount += 1\n",
    "\n",
    "\tcount +=1\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "for keys in sorted (superDict):\n",
    "\tif(superDict[keys]['SaleCondition'] != \"Normal\"):\n",
    "\t\tprint str(keys) + \"\\t\" + str(superDict[keys]['SaleCondition'])\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n",
    "    \"\"\" convert dictionary to numpy array of features\n",
    "        remove_NaN = True will convert \"NaN\" string to 0.0\n",
    "        remove_all_zeroes = True will omit any data points for which\n",
    "            all the features you seek are 0.0\n",
    "        remove_any_zeroes = True will omit any data points for which\n",
    "            any of the features you seek are 0.0\n",
    "        sort_keys = True sorts keys by alphabetical order. Setting the value as\n",
    "            a string opens the corresponding pickle file with a preset key\n",
    "            order (this is used for Python 3 compatibility, and sort_keys\n",
    "            should be left as False for the course mini-projects).\n",
    "        NOTE: first feature is assumed to be 'poi' and is not checked for\n",
    "            removal for zero or missing values.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return_list = []\n",
    "\n",
    "    # Key order - first branch is for Python 3 compatibility on mini-projects,\n",
    "    # second branch is for compatibility on final project.\n",
    "    if isinstance(sort_keys, str):\n",
    "        import pickle\n",
    "        keys = pickle.load(open(sort_keys, \"rb\"))\n",
    "    elif sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        tmp_list = []\n",
    "        for feature in features:\n",
    "            try:\n",
    "                dictionary[key][feature]\n",
    "            except KeyError:\n",
    "                print \"error: key \", feature, \" not present\"\n",
    "                return\n",
    "            value = dictionary[key][feature]\n",
    "            if value==\"NaN\" and remove_NaN:\n",
    "                value = 0\n",
    "            tmp_list.append( float(value) )\n",
    "\n",
    "        # Logic for deciding whether or not to add the data point.\n",
    "        append = True\n",
    "        # exclude 'poi' class as criteria.\n",
    "        if features[0] == 'poi':\n",
    "            test_list = tmp_list[1:]\n",
    "        else:\n",
    "            test_list = tmp_list\n",
    "        ### if all features are zero and you want to remove\n",
    "        ### data points that are all zero, do that here\n",
    "        if remove_all_zeroes:\n",
    "            append = False\n",
    "            for item in test_list:\n",
    "                if item != 0 and item != \"NaN\":\n",
    "                    append = True\n",
    "                    break\n",
    "        ### if any features for a given data point are zero\n",
    "        ### and you want to remove data points with any zeroes,\n",
    "        ### handle that here\n",
    "        if remove_any_zeroes:\n",
    "            if 0 in test_list or \"NaN\" in test_list:\n",
    "                append = False\n",
    "        ### Append the data point if flagged for addition.\n",
    "        if append:\n",
    "            return_list.append( np.array(tmp_list) )\n",
    "\n",
    "    return np.array(return_list)\n",
    "\n",
    "\n",
    "def targetFeatureSplit( data ):\n",
    "    \"\"\" \n",
    "        given a numpy array like the one returned from\n",
    "        featureFormat, separate out the first feature\n",
    "        and put it into its own list (this should be the \n",
    "        quantity you want to predict)\n",
    "        return targets and features as separate lists\n",
    "        (sklearn can generally handle both lists and numpy arrays as \n",
    "        input formats when training/predicting)\n",
    "    \"\"\"\n",
    "\n",
    "    target = []\n",
    "    features = []\n",
    "    for item in data:\n",
    "        target.append( item[0] )\n",
    "        features.append( item[1:] )\n",
    "\n",
    "    return target, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
